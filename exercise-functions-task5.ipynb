{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:02:17.690310Z","iopub.execute_input":"2025-03-10T17:02:17.690630Z","iopub.status.idle":"2025-03-10T17:02:18.317569Z","shell.execute_reply.started":"2025-03-10T17:02:17.690602Z","shell.execute_reply":"2025-03-10T17:02:18.316477Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"#  Mean Squared Error (MSE)","metadata":{}},{"cell_type":"code","source":"\ndef mse(y_true, y_pred):\n    n = len(y_true)\n    return sum((y_true[i] - y_pred[i]) ** 2 for i in range(n)) / n\n\n# Sample data\ny_true = [3, -0.5, 2, 7]\ny_pred = [2.5, 0.0, 2, 8]\n\nresult_mse = mse(y_true, y_pred)\nprint(\"Mean Squared Error (MSE):\", result_mse)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:02:18.319461Z","iopub.execute_input":"2025-03-10T17:02:18.320073Z","iopub.status.idle":"2025-03-10T17:02:18.326743Z","shell.execute_reply.started":"2025-03-10T17:02:18.320042Z","shell.execute_reply":"2025-03-10T17:02:18.325381Z"}},"outputs":[{"name":"stdout","text":"Mean Squared Error (MSE): 0.375\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"#  Root Mean Squared Error (RMSE)","metadata":{}},{"cell_type":"code","source":"\ndef mse(y_true, y_pred):\n    n = len(y_true)\n    return sum((y_true[i] - y_pred[i]) ** 2 for i in range(n)) / n\n\ndef rmse(y_true, y_pred):\n    return mse(y_true, y_pred) ** 0.5\n\n# Sample data (same as above)\ny_true = [3, -0.5, 2, 7]\ny_pred = [2.5, 0.0, 2, 8]\n\nresult_rmse = rmse(y_true, y_pred)\nprint(\"Root Mean Squared Error (RMSE):\", result_rmse)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:02:18.328042Z","iopub.execute_input":"2025-03-10T17:02:18.328411Z","iopub.status.idle":"2025-03-10T17:02:18.351046Z","shell.execute_reply.started":"2025-03-10T17:02:18.328376Z","shell.execute_reply":"2025-03-10T17:02:18.349940Z"}},"outputs":[{"name":"stdout","text":"Root Mean Squared Error (RMSE): 0.6123724356957945\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Cosine Similarity","metadata":{}},{"cell_type":"code","source":"\ndef cosine_similarity(a, b):\n    dot_product = sum(a[i] * b[i] for i in range(len(a)))\n    norm_a = sum(x ** 2 for x in a) ** 0.5\n    norm_b = sum(x ** 2 for x in b) ** 0.5\n    if norm_a == 0 or norm_b == 0:\n        return 0  # Avoid division by zero\n    return dot_product / (norm_a * norm_b)\n\n# Sample vectors\nvector1 = [1, 2, 3]\nvector2 = [4, 5, 6]\n\nresult_cos = cosine_similarity(vector1, vector2)\nprint(\"Cosine Similarity:\", result_cos)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:02:18.352236Z","iopub.execute_input":"2025-03-10T17:02:18.352601Z","iopub.status.idle":"2025-03-10T17:02:18.371813Z","shell.execute_reply.started":"2025-03-10T17:02:18.352574Z","shell.execute_reply":"2025-03-10T17:02:18.370633Z"}},"outputs":[{"name":"stdout","text":"Cosine Similarity: 0.9746318461970762\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"#  Linear Regression","metadata":{}},{"cell_type":"code","source":"\ndef linear_regression(x, y):\n    n = len(x)\n    mean_x = sum(x) / n\n    mean_y = sum(y) / n\n    numerator = sum((x[i] - mean_x) * (y[i] - mean_y) for i in range(n))\n    denominator = sum((x[i] - mean_x) ** 2 for i in range(n))\n    slope = numerator / denominator\n    intercept = mean_y - slope * mean_x\n    return slope, intercept\n\n# Sample data\nx_vals = [1, 2, 3, 4, 5]\ny_vals = [2, 4, 5, 4, 5]\n\nslope, intercept = linear_regression(x_vals, y_vals)\nprint(\"Linear Regression Slope:\", slope)\nprint(\"Linear Regression Intercept:\", intercept)\n\n# Optionally, show predicted values\npredictions = [slope * x + intercept for x in x_vals]\nprint(\"Predicted values:\", predictions)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:02:18.372878Z","iopub.execute_input":"2025-03-10T17:02:18.373180Z","iopub.status.idle":"2025-03-10T17:02:18.395154Z","shell.execute_reply.started":"2025-03-10T17:02:18.373158Z","shell.execute_reply":"2025-03-10T17:02:18.393825Z"}},"outputs":[{"name":"stdout","text":"Linear Regression Slope: 0.6\nLinear Regression Intercept: 2.2\nPredicted values: [2.8000000000000003, 3.4000000000000004, 4.0, 4.6, 5.2]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"#  Softmax Function","metadata":{}},{"cell_type":"code","source":"\ndef softmax(x):\n    # Using 2.71828 as an approximation for e\n    exps = [2.71828 ** i for i in x]\n    total = sum(exps)\n    return [j / total for j in exps]\n\n# Sample data for softmax\nvalues = [2, 1, 0]\nresult_softmax = softmax(values)\nprint(\"Softmax:\", result_softmax)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:02:18.397410Z","iopub.execute_input":"2025-03-10T17:02:18.397759Z","iopub.status.idle":"2025-03-10T17:02:18.418975Z","shell.execute_reply.started":"2025-03-10T17:02:18.397731Z","shell.execute_reply":"2025-03-10T17:02:18.417826Z"}},"outputs":[{"name":"stdout","text":"Softmax: [0.6652407656915682, 0.24472856574435606, 0.09003066856407584]\n","output_type":"stream"}],"execution_count":6}]}